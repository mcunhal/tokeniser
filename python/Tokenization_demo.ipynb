{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tokenization Demo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Init Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init(spark_home=r'/home/mcunhal/spark')\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Tokenizer\")\\\n",
    "    .config(\"spark.sql.warehouse.dir\", '/home/mcunhal/demo_tokenization/')\\\n",
    "    .enableHiveSupport()\\\n",
    "    .master('spark://192.168.1.229:7077')\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS demo_tokenization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(r\"CREATE TABLE IF NOT EXISTS demo_tokenization.RAW_DATA(\\\n",
    "    iban STRING,\\\n",
    "    nino STRING,\\\n",
    "    first_name STRING,\\\n",
    "    last_name STRING,\\\n",
    "    email STRING,\\\n",
    "    gender STRING,\\\n",
    "    ip_address STRING,\\\n",
    "    post_code STRING,\\\n",
    "    city STRING,\\\n",
    "    country STRING,\\\n",
    "    balance DOUBLE,\\\n",
    "    created_on STRING\\\n",
    ")\\\n",
    "ROW FORMAT DELIMITED FIELDS TERMINATED BY ','\\\n",
    "STORED AS TEXTFILE\\\n",
    "\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import base64\n",
    "import hashlib\n",
    "from Crypto.Cipher import AES\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import lit\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(s):\n",
    "    return s + (32 - len(s) % 32) * chr(32 - len(s) % 32)\n",
    "\n",
    "def unpad(s):\n",
    "    return s[:-ord(s[len(s)-1:])]\n",
    "\n",
    "def generate_key(seed):\n",
    "    return hashlib.sha256(seed.encode()).digest()\n",
    "\n",
    "def generate_key_string(seed):\n",
    "    key = generate_key(seed)\n",
    "    return base64.b64encode(key).decode('utf-8')\n",
    "\n",
    "def encrypt(key, raw):\n",
    "    raw = pad(raw)\n",
    "    key = generate_key(key)\n",
    "    iv = b'h\\r\\xef\\x10\\x8e\\x1e\\x8e\\xd08\\xb7iW\\x93\\xea-\\xd2'\n",
    "    cipher = AES.new(key, AES.MODE_CBC, iv)\n",
    "    return base64.b64encode(cipher.encrypt(raw)).decode('utf-8')\n",
    "\n",
    "def decrypt(key ,enc):\n",
    "    enc = base64.b64decode(enc.encode('utf-8'))\n",
    "    iv = b'h\\r\\xef\\x10\\x8e\\x1e\\x8e\\xd08\\xb7iW\\x93\\xea-\\xd2'\n",
    "    key = base64.b64decode(key.encode('utf-8'))\n",
    "    cipher = AES.new(key, AES.MODE_CBC, iv)\n",
    "    return unpad(cipher.decrypt(enc)).decode('utf-8')\n",
    "\n",
    "\n",
    "def postcode_trim(data, depth=1):\n",
    "    regex = re.compile('^([a-zA-Z]{1,})([0-9]{1,2}) ?(?:([0-9])([a-zA-Z])([a-zA-Z]))?$')\n",
    "    if re.match(regex,data):\n",
    "        parsed_postcode = re.split(regex,data)\n",
    "        return_postcode = ''.join([('' if i+1 !=3 else ' ') + parsed_postcode[i+1] for i in range(depth)])\n",
    "       \n",
    "        return return_postcode\n",
    "    else:\n",
    "        return None    \n",
    "def encode_number(data):\n",
    "    return data*97.5 +100.42\n",
    "\n",
    "def decode_number(data):\n",
    "    return (data-100.42)/97.5\n",
    "\n",
    "def bin_number(data,bins,min_bin,max_bin):\n",
    "    bins = np.linspace(min_bin, max_bin, bins)\n",
    "    \n",
    "    binned = np.digitize(data,bins,right=True)\n",
    "    \n",
    "    if binned == len(bins):\n",
    "        return max_bin\n",
    "    else:\n",
    "        return float(bins[binned])\n",
    "\n",
    "def apply_encoding(encode_type,data,*args,):\n",
    "    if encode_type == 'tokenize':\n",
    "        if args:\n",
    "            key=args[0]\n",
    "        else:\n",
    "            key='adasdadnfdm 4po435lkdrjkwera'\n",
    "        return encrypt(key,data)\n",
    "    \n",
    "    if encode_type == 'hash':  \n",
    "        return generate_key_string(data)  \n",
    "    \n",
    "    if encode_type == 'postcode':        \n",
    "        if args:\n",
    "            depth = args[0]\n",
    "        else:\n",
    "            depth = 1        \n",
    "        return postcode_trim(data,depth)\n",
    "    \n",
    "    if encode_type == 'number':\n",
    "        return encode_number(data)\n",
    "    \n",
    "    if encode_type == 'bin_number':\n",
    "        '''\n",
    "        args[0] -> bin size\n",
    "        args[1] -> min value\n",
    "        args[2] -> max value\n",
    "        '''\n",
    "        if len(args) < 3:\n",
    "            raise ValueError('Number of bins, min and max value need to be provided')\n",
    "        else:\n",
    "            return bin_number(data,args[0],args[1],args[2])\n",
    "        \n",
    "    raise ValueError(\"Encode type {} doesn't exist\".format(encode_type))\n",
    "        \n",
    "def decode(encode_type,data,*args):\n",
    "    if encode_type == 'tokenize':\n",
    "        if args:\n",
    "            key=args[0]\n",
    "        else:\n",
    "            key=generate_key_string('adasdadnfdm 4po435lkdrjkwera')\n",
    "        return decrypt(key,data)\n",
    "\n",
    "    if encode_type == 'number':\n",
    "        return decode_number(data)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Types:\n",
    " - tokenize:\n",
    "  - Tokenizes a string using a predefined key or by using a submitted key;\n",
    "  - Based on AES;\n",
    "  - This tokenization is reversible;\n",
    " - hash:\n",
    "  - Hashes a string using sha256;\n",
    "  - Non reversible;\n",
    " - encode_number:\n",
    "  - Tokenizes a number by using a predefined function;\n",
    "  - Function is monotonic, thus enabling some comparisons;\n",
    "  - Reversible;\n",
    "  - Easy to crack;\n",
    " - bin_number;\n",
    "  - Outputs a 'binned' value based on min,max and number of bins;\n",
    " - postcode_trim:\n",
    "  - Trims a postcode, based on a a depth;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non reversible tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.84210526315792\n",
      "E13 9\n",
      "VQD/l/UhfjqP+ge/ZukG8Dvtd05Ozy01yI8O9RB9I0g=\n"
     ]
    }
   ],
   "source": [
    "print(apply_encoding('bin_number',32,20,-100,100))\n",
    "print(apply_encoding('postcode','E13 9NJ',3))\n",
    "print(apply_encoding('hash','1asd23'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reversible tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xy0CK7dTuqmhvWFkW8u9ibM55Al0SrP17kDHRDxNuTU=\n",
      "K83JCF7nBiiybG8HUpWsuqA1ym4IlKER3D/w3fjM7w4=\n",
      "Miguel\n"
     ]
    }
   ],
   "source": [
    "key_value = apply_encoding('hash','basdasdbasd')\n",
    "print(key_value)\n",
    "encoded_value = apply_encoding('tokenize','Miguel','basdasdbasd')\n",
    "print(encoded_value)\n",
    "print(decode('tokenize',encoded_value,key_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgTaWqOdWc+iA0G/CkWBf3ahJ78oxSTUTAJueHP2J/M=\n",
      "Miguel\n"
     ]
    }
   ],
   "source": [
    "encoded_value = apply_encoding('tokenize','Miguel')\n",
    "print(encoded_value)\n",
    "print(decode('tokenize',encoded_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120415.42\n",
      "1234.0\n"
     ]
    }
   ],
   "source": [
    "encoded_value = apply_encoding('number',1234)\n",
    "print(encoded_value)\n",
    "print(decode('number',encoded_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registring the functions in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "udf_apply_encoding = spark.udf.register(\"apply_encoding\", apply_encoding)\n",
    "udf_decode = spark.udf.register(\"decode\", decode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"demo_tokenization.raw_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the functions are working in spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|apply_encoding(tokenize, iban, nino)|\n",
      "+------------------------------------+\n",
      "|                jCEzkLhLZxLQYssIo...|\n",
      "|                koFe1SmwoIOwdaf/M...|\n",
      "|                sv0sqcHxk58vspWOj...|\n",
      "|                DFjmcBbuU6/HEgW5P...|\n",
      "|                z38+Goe3/K1UQxzJ9...|\n",
      "|                UZnrajyjBkVoqqiv9...|\n",
      "|                uSq3furfsZEqF+rDF...|\n",
      "|                hMrjccPTmBI4gGsJE...|\n",
      "|                5CYNieeFU4f+4H3c1...|\n",
      "|                q6SQvmYa9FKuG7SpM...|\n",
      "|                yTmoYS1kVsQKWGnsy...|\n",
      "|                pADhr2l6keXZ/D9Qc...|\n",
      "|                S0LggZ9rzyi4LCq2Y...|\n",
      "|                VC3HqdPqKBvIrXVJ3...|\n",
      "|                dgNKye3l/Q26A4Ibi...|\n",
      "|                8K4PZTQzI8KRQ5yc0...|\n",
      "|                UAfLnPFd4gWlGSn1m...|\n",
      "|                YNMpaOk6eD5WcreFj...|\n",
      "|                FxF4Jf/kCLYZnuDfu...|\n",
      "|                jPmDe1xX/eH866ure...|\n",
      "+------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(udf_apply_encoding(lit(\"tokenize\"),\"iban\",\"nino\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------+\n",
      "|apply_encoding(bin_number, balance, 40, -100000, 10000)|\n",
      "+-------------------------------------------------------+\n",
      "|                                                  10000|\n",
      "|                                                10000.0|\n",
      "|                                                  10000|\n",
      "|                                                10000.0|\n",
      "|                                                10000.0|\n",
      "|                                                  10000|\n",
      "|                                                10000.0|\n",
      "|                                                10000.0|\n",
      "|                                                10000.0|\n",
      "|                                                10000.0|\n",
      "|                                                10000.0|\n",
      "|                                                10000.0|\n",
      "|                                                  10000|\n",
      "|                                                10000.0|\n",
      "|                                      7179.487179487172|\n",
      "|                                                  10000|\n",
      "|                                      7179.487179487172|\n",
      "|                                                10000.0|\n",
      "|                                                  10000|\n",
      "|                                                  10000|\n",
      "+-------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(udf_apply_encoding(lit(\"bin_number\"),\"balance\",lit(40),lit(-100000),lit(10000))).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+---------+\n",
      "|apply_encoding(postcode, post_code, 1)|post_code|\n",
      "+--------------------------------------+---------+\n",
      "|                                    DL|     DL10|\n",
      "|                                     S|       S1|\n",
      "|                                  null|      W1F|\n",
      "|                                     L|      L33|\n",
      "|                                    LN|      LN6|\n",
      "|                                    LE|     LE14|\n",
      "|                                    LE|     LE15|\n",
      "|                                    NN|      NN4|\n",
      "|                                    DN|     DN36|\n",
      "|                                  null|     EC1V|\n",
      "|                                    CT|     CT16|\n",
      "|                                    NE|     NE46|\n",
      "|                                  null|     WC1B|\n",
      "|                                  null|     WC1B|\n",
      "|                                    LS|      LS6|\n",
      "|                                    BS|     BS14|\n",
      "|                                    BD|     BD23|\n",
      "|                                    LS|      LS9|\n",
      "|                                  null|     EC3M|\n",
      "|                                    OX|      OX7|\n",
      "+--------------------------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(udf_apply_encoding(lit(\"postcode\"),\"post_code\",lit(1)),\"post_code\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------+\n",
      "|apply_encoding(number, balance)|\n",
      "+-------------------------------+\n",
      "|                     1239725.17|\n",
      "|                      871701.67|\n",
      "|                     1146037.42|\n",
      "|                      930162.67|\n",
      "|                      757002.67|\n",
      "|                     1137018.67|\n",
      "|                      848828.17|\n",
      "|              885965.9199999999|\n",
      "|              942320.9199999999|\n",
      "|                      786632.92|\n",
      "|                      791624.92|\n",
      "|                      824014.42|\n",
      "|                     1187747.92|\n",
      "|                      772163.92|\n",
      "|                      596654.17|\n",
      "|                     1084466.17|\n",
      "|                      485845.42|\n",
      "|              938323.4199999999|\n",
      "|                     1146729.67|\n",
      "|                     1206545.92|\n",
      "+-------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(udf_apply_encoding(lit(\"number\"),\"balance\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok = df\\\n",
    "    .withColumn(\"key\",udf_apply_encoding(lit(\"hash\"),\"nino\"))\\\n",
    "    .withColumn(\"iban\",udf_apply_encoding(lit(\"tokenize\"),\"first_name\",\"nino\"))\\\n",
    "    .withColumn(\"first_name\",udf_apply_encoding(lit(\"tokenize\"),\"first_name\",\"nino\"))\\\n",
    "    .withColumn(\"last_name\",udf_apply_encoding(lit(\"tokenize\"),\"last_name\",\"nino\"))\\\n",
    "    .withColumn(\"email\",udf_apply_encoding(lit(\"tokenize\"),\"email\",\"nino\"))\\\n",
    "    .withColumn(\"gender\",udf_apply_encoding(lit(\"tokenize\"),\"gender\",\"nino\"))\\\n",
    "    .withColumn(\"ip_address\",udf_apply_encoding(lit(\"tokenize\"),\"ip_address\",\"nino\"))\\\n",
    "    .withColumn(\"post_code_unique\",udf_apply_encoding(lit(\"tokenize\"),\"post_code\",\"nino\"))\\\n",
    "    .withColumn(\"post_code\",udf_apply_encoding(lit(\"tokenize\"),\"post_code\"))\\\n",
    "    .withColumn(\"balance\",udf_apply_encoding(lit(\"number\"),\"balance\"))\\\n",
    "    .withColumn(\"bin_balance\",udf_apply_encoding(lit(\"bin_number\"),\"balance\",lit(1001),lit(-10000),lit(100000)))\\\n",
    "    .withColumn(\"nino\",udf_apply_encoding(lit(\"tokenize\"),\"nino\",\"nino\"))\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tok.write.saveAsTable('demo_tokenization.tokenized_data',format=\"parquet\",mode=\"append\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"Truncate table demo_tokenization.raw_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization Showcase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|           post_code|count(1)|\n",
      "+--------------------+--------+\n",
      "|gP+EBWypryqgXUULi...|     149|\n",
      "|TChH2w4KBeQUAnrs2...|     143|\n",
      "|yeECKNCaiEIQMWlDq...|     125|\n",
      "|Ewldi3upBOmCaULBF...|      91|\n",
      "|/yuAkv5UWD4VG7tUg...|      87|\n",
      "|5IiSPFWRQ88E4OG5+...|      83|\n",
      "|ddssSe9WlWdv9/RkB...|      83|\n",
      "|3DX9tKZO4yEjrH9ru...|      82|\n",
      "|g76CrtbUh1czU7ES/...|      82|\n",
      "|Z3sW3uM9GAnGTtohp...|      79|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select post_code,count(*) from demo_tokenization.tokenized_data group by post_code order by count(*) desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|    post_code_unique|count(1)|\n",
      "+--------------------+--------+\n",
      "|8c3+A4KmqQO5zD8R7...|       1|\n",
      "|H7O8mk7V+vlWK9e8n...|       1|\n",
      "|ANOrDdtTqNcg/5+64...|       1|\n",
      "|Yc6Hje25md0h0tMd0...|       1|\n",
      "|9YziBI0ZnzCiDi+h4...|       1|\n",
      "|4En302e6Fc5H+lzxD...|       1|\n",
      "|whqC3k87aPYOYJd3O...|       1|\n",
      "|GdNMxHF5Lrl+o2Z1n...|       1|\n",
      "|iP7H0m0j7U6aagx1L...|       1|\n",
      "|UHkWqijtqIxHC9bbi...|       1|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select post_code_unique,count(*) from demo_tokenization.tokenized_data group by post_code_unique order by count(*) desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+--------+\n",
      "|decode(tokenize, post_code)|count(1)|\n",
      "+---------------------------+--------+\n",
      "|                       CV35|     149|\n",
      "|                       LE15|     143|\n",
      "|                       BD23|     125|\n",
      "|                       CH48|      91|\n",
      "|                       RG20|      87|\n",
      "|                       SW1E|      83|\n",
      "|                       EC1V|      83|\n",
      "|                        M34|      82|\n",
      "|                        LS9|      82|\n",
      "|                       OX12|      79|\n",
      "+---------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select decode('tokenize',post_code),count(*) from demo_tokenization.tokenized_data group by decode('tokenize',post_code) order by count(*) desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------+\n",
      "|decode(tokenize, post_code_unique, key)|count(1)|\n",
      "+---------------------------------------+--------+\n",
      "|                                   CV35|     149|\n",
      "|                                   LE15|     143|\n",
      "|                                   BD23|     125|\n",
      "|                                   CH48|      91|\n",
      "|                                   RG20|      87|\n",
      "|                                   SW1E|      83|\n",
      "|                                   EC1V|      83|\n",
      "|                                    M34|      82|\n",
      "|                                    LS9|      82|\n",
      "|                                   OX12|      79|\n",
      "+---------------------------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select decode('tokenize',post_code_unique,key),count(*) from demo_tokenization.tokenized_data group by 1 order by count(*) desc limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customschema = StructType([StructField('iban', StringType(), True),\n",
    "                    StructField('nino', StringType(), True),\n",
    "                    StructField('first_name', StringType(), True),\n",
    "                    StructField('last_name', StringType(), True),\n",
    "                    StructField('email', StringType(), True),\n",
    "                    StructField('gender', StringType(), True),\n",
    "                    StructField('ip_address', StringType(), True),\n",
    "                    StructField('post_code', StringType(), True),\n",
    "                    StructField('city', StringType(), True),\n",
    "                    StructField('country', StringType(), True),\n",
    "                    StructField('balance', DoubleType(), True),\n",
    "                    StructField('created_on', StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\")\\\n",
    "    .option(\"header\", \"true\")\\\n",
    "    .schema(customschema)\\\n",
    "    .load(\"/home/mcunhal/demo_tokenization/input/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(r\"CREATE TABLE IF NOT EXISTS demo_tokenization.TOKENIZED_DATA(\\\n",
    "    iban STRING,\\\n",
    "    nino STRING,\\\n",
    "    first_name STRING,\\\n",
    "    last_name STRING,\\\n",
    "    email STRING,\\\n",
    "    gender STRING,\\\n",
    "    ip_address STRING,\\\n",
    "    post_code STRING,\\\n",
    "    city STRING,\\\n",
    "    country STRING,\\\n",
    "    balance DOUBLE,\\\n",
    "    bin_balance DOUBLE,\\\n",
    "    created_on STRING\\\n",
    ")\\\n",
    "STORED AS PARQUET\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
